---
title: "Algorithm comparison"
author: "Eleni Nisioti"
date: "May 13, 2017"
output:
  html_document:
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( echo = FALSE,warning= FALSE, message= FALSE)
project_dir <- getwd()
load("comparison_info.Rdata")
install_dir <- data$install_dir
knitr::opts_knit$set(root.dir = install_dir)
```

## Description
This is an automatic report generated for the comparison of different machine learning models on benchmark datasets. Performances of models have been gathered during our experiments and are stored under [workspace/benchmarks/thesis_benchmarks.csv](workspace/benchmarks/thesis_benchmarks.csv). You can specify your own file of benchmarks upon calling [experiment.R](experiment.R).

Comparison of algorithms is performed by applying statistical hypothesis testing and providing performance profile plots.

## Hypothesis testing
`r str(data)`
The number of algorithms compared was `r ncol(data$results)` and we avoided parametric methods due to lack of certainty about assumptions of sample's probability distribution. Thus, testing technique used was `r data$method`, which resulted in a p-value of `r data$p_value` for confidence level `r data$conf_level`. The null hypothesis can therefore `r if(data$Null_Hypothesis) cat("not")` be rejected. 

Pairs of methods that differ significantly include:

```{r, results='pairs',  message = TRUE}
for(i in seq(1, length(data$post_hoc$r_index))){
cat(paste(data$post_hoc$r_index[i], "and",data$post_hoc$c_index[i], sep = " " )) 
cat('\n')  
}
```


## Performance profile plot
```{r print_perf, fig.cap= "**Figure 1** *Performance profie plot of compared algorithms.*"}
source("build_script.R")
performances <- data$results
file_name <- "perf_prof"
performances$X <- NULL
perform_profiles <- data.frame()
# find minimum of each column
alg_min <- apply(performances, 1, function(x) min(x, na.rm = TRUE))
# compute ratio of each element by dividing with smallest dataset performance
perform_profiles <- performances/alg_min
# replace all NaN's with twice the max ratio (a Nan represents an unsolved dataset)
max_ratio <- max(perform_profiles)
perform_profiles[is.na(perform_profiles)] <- 2*max_ratio
# sort each column in ascengind order
perform_profiles <- as.data.frame(apply(perform_profiles, 2, sort))
# -------- plot stair graph (one line per algorithm, showing what percentage of algorithms performs better on each dataset)--------
# find points to plot
perform_profiles$x <- (seq(1, nrow(perform_profiles)))/nrow(perform_profiles)
# plot
perform_profiles <- melt(perform_profiles ,  id.vars = 'x', variable.name = 'algorithm')
ggplot(perform_profiles, aes(value, x)) + geom_line(aes(colour = algorithm)) +
      ggtitle('Performance profile plot') + 
      labs(x="t",y="P")
```